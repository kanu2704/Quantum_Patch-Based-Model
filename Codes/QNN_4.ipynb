{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install qiskit==1.4.2 tensorflow numpy pandas matplotlib pennylane silence-tensorflow pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld7ru0Qi3_rr",
        "outputId": "ef9bd42f-3837-4366-ca9c-619bfd5cfbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit==1.4.2\n",
            "  Downloading qiskit-1.4.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.41.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting silence-tensorflow\n",
            "  Downloading silence_tensorflow-1.2.3.tar.gz (7.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rustworkx>=0.15.0 (from qiskit==1.4.2)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.4.2) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.4.2) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.4.2) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.4.2) (2.9.0.post0)\n",
            "Collecting stevedore>=3.0.0 (from qiskit==1.4.2)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit==1.4.2) (4.13.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit==1.4.2)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.41 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.41->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.265.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit==1.4.2)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit==1.4.2) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading qiskit-1.4.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane-0.41.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.29.265.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: silence-tensorflow\n",
            "  Building wheel for silence-tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silence-tensorflow: filename=silence_tensorflow-1.2.3-py3-none-any.whl size=6749 sha256=d5ba5d242e82a5270f45157468fd3d24e74d8a3a6dd0064d88e1faaad1f64a4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/5f/7e/afa8e22bf573d8aa309e5c8aed0d1a327076c5df2e12f68612\n",
            "Successfully built silence-tensorflow\n",
            "Installing collected packages: silence-tensorflow, appdirs, symengine, scipy-openblas32, rustworkx, pbr, autoray, stevedore, diastatic-malt, qiskit, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pbr-6.1.1 pennylane-0.41.1 pennylane-lightning-0.41.1 qiskit-1.4.2 rustworkx-0.16.0 scipy-openblas32-0.3.29.265.0 silence-tensorflow-1.2.3 stevedore-5.4.1 symengine-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install pennylane qiskit qiskit-ibm-runtime pennylane-qiskit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69M6owq4CfXi",
        "outputId": "c27022d4-e5f8-4a53-b158-08e0770288a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting qiskit-ibm-runtime\n",
            "  Downloading qiskit_ibm_runtime-0.40.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pennylane-qiskit\n",
            "  Downloading pennylane_qiskit-0.41.0.post0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.7.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.41 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (5.4.1)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.13.0)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-runtime)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (2.4.0)\n",
            "Collecting ibm-platform-services>=0.22.6 (from qiskit-ibm-runtime)\n",
            "  Downloading ibm_platform_services-0.66.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (2.11.5)\n",
            "INFO: pip is looking at multiple versions of pennylane-qiskit to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pennylane-qiskit\n",
            "  Downloading pennylane_qiskit-0.41.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading pennylane_qiskit-0.40.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading PennyLane_qiskit-0.40.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading PennyLane_qiskit-0.39.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading PennyLane_qiskit-0.39.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting qiskit-aer (from pennylane-qiskit)\n",
            "  Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting qiskit-ibm-runtime\n",
            "  Downloading qiskit_ibm_runtime-0.29.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting qiskit-ibm-provider (from pennylane-qiskit)\n",
            "  Downloading qiskit_ibm_provider-0.11.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting sympy>=1.3 (from qiskit)\n",
            "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (1.8.0)\n",
            "Collecting ibm_cloud_sdk_core<4.0.0,>=3.24.1 (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime)\n",
            "  Downloading ibm_cloud_sdk_core-3.24.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning>=0.41->pennylane) (0.3.29.265.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime) (43.0.3)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-runtime)\n",
            "  Downloading pyspnego-0.11.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer->pennylane-qiskit) (5.9.5)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider->pennylane-qiskit) (15.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from ibm_cloud_sdk_core<4.0.0,>=3.24.1->ibm-platform-services>=0.22.6->qiskit-ibm-runtime) (2.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime) (2.22)\n",
            "Downloading PennyLane_qiskit-0.39.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_ibm_runtime-0.29.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_platform_services-0.66.1-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.9/363.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_ibm_provider-0.11.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_cloud_sdk_core-3.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspnego-0.11.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy, ibm_cloud_sdk_core, pyspnego, ibm-platform-services, requests-ntlm, qiskit-aer, qiskit-ibm-runtime, qiskit-ibm-provider, pennylane-qiskit\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ibm-platform-services-0.66.1 ibm_cloud_sdk_core-3.24.1 pennylane-qiskit-0.39.0 pyspnego-0.11.2 qiskit-aer-0.17.1 qiskit-ibm-provider-0.11.0 qiskit-ibm-runtime-0.29.0 requests-ntlm-1.3.0 sympy-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hROIeBovBTwM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl0DG6gmPJre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913b5c53-4326-4755-8592-1d6c44cc5cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import numpy as np\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "import pennylane as qml\n",
        "from qiskit import QuantumCircuit, transpile\n",
        "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')\n",
        "from silence_tensorflow import silence_tensorflow\n",
        "silence_tensorflow()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_ibm_runtime import QiskitRuntimeService\n",
        "\n",
        "# Replace YOUR_TOKEN_HERE with your actual token\n",
        "QiskitRuntimeService.save_account(\n",
        "    channel=\"ibm_quantum\",\n",
        "    token=\"a6cf8f18c09783ed8411a5094f43d0b5d63f904f1e98ef3e8053ac626a03326218796711cc9b1c3ba98a8336b344a23c867a3f51eb188a26f1e67a811e6d34f2\",overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "ENGRVAeKKf4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_ibm_runtime import QiskitRuntimeService\n",
        "\n",
        "service = QiskitRuntimeService(channel=\"ibm_quantum\")\n",
        "backends = service.backends()\n",
        "print(f\"Available backends: {[b.name for b in backends]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9L4MsRcKjlu",
        "outputId": "ae1c9f25-dc0c-47a7-cbfb-5b0a6e1cf0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available backends: ['ibm_brisbane', 'ibm_sherbrooke']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QATKCYqDXCJD"
      },
      "source": [
        "\n",
        "\n",
        "Selects 30 samples each from MNIST classes 0 and 5 for training.\n",
        "\n",
        "Shuffles and normalizes the training images.\n",
        "\n",
        "Test set includes all 10 classes, not just 0 and 5.\n",
        "\n",
        "Labels are not yet converted to binary (0 and 1).\n",
        "\n",
        "Prints shapes and class distributions for quick checks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTFhJ2XTPbmZ",
        "outputId": "4e669df6-b5ec-4bd6-f7e5-e19180ff58f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Training data shape: (60, 28, 28)\n",
            "Training labels shape: (60,)\n",
            "Training class distribution: [30  0  0  0  0 30]\n",
            "Test data shape: (1000, 28, 28)\n",
            "Test labels shape: (1000,)\n",
            "Test class distribution: [100 100 100 100 100 100 100 100 100 100]\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Filter training data for classes 0 and 5 (30 samples each)\n",
        "def get_class_samples(images, labels, target_class, num_samples):\n",
        "    \"\"\"Get specified number of samples for a target class\"\"\"\n",
        "    class_indices = np.where(labels == target_class)[0]\n",
        "    selected_indices = class_indices[:num_samples]\n",
        "    return images[selected_indices], labels[selected_indices]\n",
        "\n",
        "# Get 30 samples each of class 0 and 5\n",
        "train_images_0, train_labels_0 = get_class_samples(train_images, train_labels, 0, 30)\n",
        "train_images_5, train_labels_5 = get_class_samples(train_images, train_labels, 5, 30)\n",
        "\n",
        "# Combine the training data\n",
        "train_images_selected = np.concatenate([train_images_0, train_images_5], axis=0)\n",
        "train_labels_selected = np.concatenate([train_labels_0, train_labels_5], axis=0)\n",
        "\n",
        "# Shuffle the training data\n",
        "shuffle_indices = np.random.permutation(len(train_images_selected))\n",
        "train_images_selected = train_images_selected[shuffle_indices]\n",
        "train_labels_selected = train_labels_selected[shuffle_indices]\n",
        "\n",
        "# Normalize training data\n",
        "train_images_selected = train_images_selected / 255.0\n",
        "train_images_selected = tf.cast(train_images_selected, tf.float32)\n",
        "\n",
        "# Convert labels to float32 as well\n",
        "train_labels_selected = tf.cast(train_labels_selected, tf.float32)\n",
        "\n",
        "# Prepare test data (100 samples from each class for comprehensive testing)\n",
        "def get_balanced_test_set(images, labels, samples_per_class=100):\n",
        "    \"\"\"Get balanced test set with specified samples per class\"\"\"\n",
        "    test_imgs = []\n",
        "    test_lbls = []\n",
        "\n",
        "    for class_id in range(10):  # MNIST has classes 0-9\n",
        "        class_indices = np.where(labels == class_id)[0]\n",
        "        selected_indices = class_indices[:samples_per_class]\n",
        "        test_imgs.append(images[selected_indices])\n",
        "        test_lbls.append(labels[selected_indices])\n",
        "\n",
        "    return np.concatenate(test_imgs), np.concatenate(test_lbls)\n",
        "\n",
        "test_images_balanced, test_labels_balanced = get_balanced_test_set(test_images, test_labels, 100)\n",
        "test_images_balanced = test_images_balanced / 255.0\n",
        "test_images_balanced = tf.cast(test_images_balanced, tf.float32)\n",
        "\n",
        "# Convert test labels to float32 as well\n",
        "test_labels_balanced = tf.cast(test_labels_balanced, tf.float32)\n",
        "\n",
        "print(f\"Training data shape: {train_images_selected.shape}\")\n",
        "print(f\"Training labels shape: {train_labels_selected.shape}\")\n",
        "print(f\"Training class distribution: {np.bincount(train_labels_selected.numpy().astype(int))}\")\n",
        "print(f\"Test data shape: {test_images_balanced.shape}\")\n",
        "print(f\"Test labels shape: {test_labels_balanced.shape}\")\n",
        "print(f\"Test class distribution: {np.bincount(test_labels_balanced.numpy().astype(int))}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend_name = backends[0].name  # Use first available\n",
        "backend = service.backend(backend_name)\n",
        "print(f\"Using backend: {backend_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbFlw2azL497",
        "outputId": "0f0466d1-da46-40fb-e60a-856284287b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: ibm_brisbane\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL4echx-XxAO"
      },
      "source": [
        "Uses PennyLane for quantum circuit simulation.\n",
        "\n",
        "Sets up a 4-qubit quantum system (n_qubits = 4).\n",
        "\n",
        "patch_size = 2 — likely used for local operations or grouping qubits.\n",
        "\n",
        "layers = 1 — defines the number of circuit layers (depth).\n",
        "\n",
        "levels = 3 — may refer to multi-level encoding or processing stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxm5PsOjRDwh"
      },
      "outputs": [],
      "source": [
        "# Quantum circuit setup\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "import math\n",
        "\n",
        "n_qubits = 4\n",
        "patch_size = 2\n",
        "layers = 1\n",
        "levels = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend_object = service.backend(backend_name)  # Get the object first\n",
        "dev = qml.device('qiskit.remote',\n",
        "                 wires=n_qubits,\n",
        "                 backend=backend_object,  # ← Pass the object\n",
        "                 shots=1024)\n",
        "# dev = qml.device('default.qubit', wires=n_qubits)"
      ],
      "metadata": {
        "id": "Mxu07t84MAUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UI9aBIXYoZM"
      },
      "source": [
        "Quantum device: Uses PennyLane's 'default.qubit' simulator with 4 qubits.\n",
        "\n",
        "Input encoding: Applies RY rotations (π * input[i]) for each qubit.\n",
        "\n",
        "Parameterized layers: Each layer includes RY rotations and CNOT entanglement.\n",
        "\n",
        "Entanglement: Uses CNOT gates in a ring pattern (i → (i+1) % n_qubits).\n",
        "\n",
        "Output: Returns Pauli-Z expectations for all qubits as circuit output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVunN3VTRMUe"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface=\"tf\", diff_method=\"parameter-shift\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    # Ensure inputs are properly shaped and cast\n",
        "    inputs = tf.cast(inputs, tf.float32)\n",
        "\n",
        "    # Feature map - make sure we only use n_qubits\n",
        "    for i in range(min(len(inputs), n_qubits)):  # Safety check\n",
        "        qml.RY(inputs[i] * pnp.pi, wires=i)\n",
        "\n",
        "    # Variational layers\n",
        "    for l in range(layers):\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(weights[l][i], wires=i)\n",
        "        for i in range(n_qubits):\n",
        "            qml.CNOT(wires=[i, (i + 1) % n_qubits])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6QnetrPY1Hw"
      },
      "source": [
        "Splits an image into non-overlapping square patches of size patch_size × patch_size.\n",
        "\n",
        "Iterates over image in steps of patch_size (both row and column).\n",
        "\n",
        "Flattens each valid patch into a 1D tensor using tf.reshape.\n",
        "\n",
        "Skips incomplete edge patches (if shape doesn't match).\n",
        "\n",
        "Returns a stacked tensor of all flattened patches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E1Ab6MCR76T"
      },
      "outputs": [],
      "source": [
        "def extract_patches(img, patch_size):\n",
        "    patches = []\n",
        "    for i in range(0, img.shape[0], patch_size):\n",
        "        for j in range(0, img.shape[1], patch_size):\n",
        "            patch = img[i:i+patch_size, j:j+patch_size]\n",
        "            if patch.shape == (patch_size, patch_size):\n",
        "                patches.append(tf.reshape(patch, [-1]))\n",
        "    return tf.stack(patches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIpXEdqzZGAt"
      },
      "source": [
        "Seeds set for both TensorFlow and PennyLane to ensure reproducibility.\n",
        "\n",
        "Initializes weights for 3 quantum layers (weights_l1, weights_l2, weights_l3).\n",
        "\n",
        "Each weight tensor has shape (layers, n_qubits).\n",
        "\n",
        "Values are drawn from a normal distribution with stddev = 0.1.\n",
        "\n",
        "Weights are marked as trainable for optimization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU758SDPSBpg"
      },
      "outputs": [],
      "source": [
        "# Initialize quantum weights\n",
        "tf.random.set_seed(42)\n",
        "pnp.random.seed(42)\n",
        "\n",
        "weights_l1 = tf.Variable(tf.random.normal((layers, n_qubits), stddev=0.1), trainable=True,dtype='float32')\n",
        "weights_l2 = tf.Variable(tf.random.normal((layers, n_qubits), stddev=0.1), trainable=True,dtype='float32')\n",
        "weights_l3 = tf.Variable(tf.random.normal((layers, n_qubits), stddev=0.1), trainable=True,dtype='float32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXgEkZc9ZdZp"
      },
      "source": [
        "Defines a simple neural network with Keras Sequential API.\n",
        "\n",
        "Input layer expects vectors of length 9.\n",
        "\n",
        "Output layer has 10 units with softmax (for multiclass classification).\n",
        "\n",
        "Uses Adam optimizer with a learning rate of 0.01.\n",
        "\n",
        "Applies sparse categorical crossentropy as the loss function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXW0BaCJSItj"
      },
      "outputs": [],
      "source": [
        "# Classical model\n",
        "classical_model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(9,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax',dtype='float32')\n",
        "])\n",
        "\n",
        "# Optimizer and loss\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5igZK89UZfeL"
      },
      "source": [
        "Extracts 2×2 patches from input image → processes through 3 quantum layers.\n",
        "\n",
        "Each quantum layer:\n",
        "\n",
        "    Runs patches through quantum_circuit.\n",
        "\n",
        "    Averages qubit outputs.\n",
        "\n",
        "    Reshapes output to smaller spatial dimensions.\n",
        "\n",
        "The image goes from 28×28 → 14×14 → 7×7 → flat vector.\n",
        "\n",
        "Output is flattened and passed into the classical model.\n",
        "\n",
        "Returns logits (raw output before softmax) from the classical dense layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB104b6jSRuI"
      },
      "outputs": [],
      "source": [
        "def forward(x_img):\n",
        "    # First layer\n",
        "    print(f\"Input image shape: {x_img.shape}\")\n",
        "    patches1 = extract_patches(x_img, patch_size)\n",
        "    print(f\"Patches1 shape: {patches1.shape}\")\n",
        "\n",
        "    q_outputs1 = []\n",
        "    for i in range(patches1.shape[0]):\n",
        "        patch = patches1[i]\n",
        "        print(f\"Patch {i} shape: {patch.shape}, values: {patch[:4]}\")  # Show first 4 values\n",
        "        # Ensure patch has exactly n_qubits elements\n",
        "        if len(patch) != n_qubits:\n",
        "            print(f\"WARNING: Patch has {len(patch)} elements, but n_qubits is {n_qubits}\")\n",
        "            patch = patch[:n_qubits]  # Truncate if too long\n",
        "        q_output1 = quantum_circuit(patch, weights_l1)\n",
        "        if isinstance(q_output1, (list, tuple)):\n",
        "            q_output1 = tf.stack(q_output1)\n",
        "        q_output1 = tf.cast(tf.math.real(q_output1), tf.float32)\n",
        "        q_output_1_avg = tf.reduce_mean(q_output1)\n",
        "        q_outputs1.append(q_output_1_avg)\n",
        "\n",
        "    q_outputs1 = tf.stack(q_outputs1)\n",
        "    q_outputs1_reshaped = tf.reshape(q_outputs1, (14, 14))\n",
        "\n",
        "    # Second layer\n",
        "    patches2 = extract_patches(q_outputs1_reshaped, patch_size)\n",
        "\n",
        "    q_outputs2 = []\n",
        "    for i in range(patches2.shape[0]):\n",
        "        patch = patches2[i]\n",
        "        q_output2 = quantum_circuit(patch, weights_l2)\n",
        "        if isinstance(q_output2, (list, tuple)):\n",
        "            q_output2 = tf.stack(q_output2)\n",
        "        q_output2 = tf.cast(tf.math.real(q_output2), tf.float32)\n",
        "        q_output_2_avg = tf.reduce_mean(q_output2)\n",
        "        q_outputs2.append(q_output_2_avg)\n",
        "\n",
        "    q_outputs2 = tf.stack(q_outputs2)\n",
        "    q_outputs2_reshaped = tf.reshape(q_outputs2, (7, 7))\n",
        "\n",
        "    # Third layer\n",
        "    patches3 = extract_patches(q_outputs2_reshaped, patch_size)\n",
        "\n",
        "    q_outputs3 = []\n",
        "    for i in range(patches3.shape[0]):\n",
        "        patch = patches3[i]\n",
        "        q_output3 = quantum_circuit(patch, weights_l3)\n",
        "        if isinstance(q_output3, (list, tuple)):\n",
        "            q_output3 = tf.stack(q_output3)\n",
        "        q_output3 = tf.cast(tf.math.real(q_output3), tf.float32)\n",
        "        q_output_3_avg = tf.reduce_mean(q_output3)\n",
        "        q_outputs3.append(q_output_3_avg)\n",
        "\n",
        "    q_outputs3 = tf.stack(q_outputs3)\n",
        "    q_outputs3_reshaped = tf.reshape(q_outputs3, (1, -1))\n",
        "\n",
        "    # Classical layer\n",
        "    logits = classical_model(q_outputs3_reshaped)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VJEVvjpZuNK"
      },
      "source": [
        "Runs forward pass on input x_img to get predictions.\n",
        "\n",
        "Computes loss using sparse categorical crossentropy with reshaped label.\n",
        "\n",
        "Calculates gradients for both quantum weights and classical model weights.\n",
        "\n",
        "Applies gradients using Adam optimizer to update all trainable parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAhoHXvwSTMq"
      },
      "outputs": [],
      "source": [
        "# @tf.function\n",
        "def train_step(x_img, y_label):\n",
        "    # Debug input types\n",
        "    tf.print(\"=== INPUT TYPES ===\")\n",
        "    tf.print(\"x_img dtype:\", x_img.dtype)\n",
        "    tf.print(\"y_label dtype:\", y_label.dtype)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Cast both inputs to ensure consistency\n",
        "        x_img = tf.cast(x_img, tf.float32)\n",
        "        y_label = tf.cast(y_label, tf.float32)\n",
        "\n",
        "        tf.print(\"After casting:\")\n",
        "        tf.print(\"x_img dtype:\", x_img.dtype)\n",
        "        tf.print(\"y_label dtype:\", y_label.dtype)\n",
        "\n",
        "        predictions = forward(x_img)\n",
        "        tf.print(\"predictions dtype:\", predictions.dtype)\n",
        "\n",
        "        loss = loss_fn(tf.reshape(y_label, (1,)), predictions)\n",
        "        tf.print(\"loss dtype:\", loss.dtype)\n",
        "\n",
        "    # Debug trainable variables types\n",
        "    tf.print(\"=== TRAINABLE VARIABLES TYPES ===\")\n",
        "    tf.print(\"weights_l1 dtype:\", weights_l1.dtype)\n",
        "    tf.print(\"weights_l2 dtype:\", weights_l2.dtype)\n",
        "    tf.print(\"weights_l3 dtype:\", weights_l3.dtype)\n",
        "\n",
        "    # Check classical model variables\n",
        "    for i, var in enumerate(classical_model.trainable_variables):\n",
        "        tf.print(f\"classical_model var {i} dtype:\", var.dtype)\n",
        "\n",
        "    trainable_vars = [weights_l1, weights_l2, weights_l3] + classical_model.trainable_variables\n",
        "\n",
        "    tf.print(\"=== BEFORE GRADIENT COMPUTATION ===\")\n",
        "    tf.print(\"About to compute gradients...\")\n",
        "\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "    tf.print(\"=== GRADIENT COMPUTATION SUCCESSFUL ===\")\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "    return loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Uvu5C_aAle"
      },
      "source": [
        "Trains for 10 epochs on 60 images (30 each of class 0 and 5).\n",
        "\n",
        "Shuffles data each epoch to improve generalization.\n",
        "\n",
        "Trains one image at a time using train_step, tracking loss and accuracy.\n",
        "\n",
        "Prints progress per epoch, including average loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "HQaxbReeSYkI",
        "outputId": "bd3e69ad-be0a-40b8-80e0-11626c0cc2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on 60 images (30 each of class 0 and 5)...\n",
            "============================================================\n",
            "=== INPUT TYPES ===\n",
            "x_img dtype: tf.float32\n",
            "y_label dtype: tf.float32\n",
            "After casting:\n",
            "x_img dtype: tf.float32\n",
            "y_label dtype: tf.float32\n",
            "Input image shape: (28, 28)\n",
            "Patches1 shape: (196, 4)\n",
            "Patch 0 shape: (4,), values: [0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The number of qubits of the circuit (127) does not match the number of qubits of the (0,)-th observable (4).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-487180370c97>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-b603bbbef9a8>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_img, y_label)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_label dtype:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions dtype:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-db0ef49a10f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(x_img)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"WARNING: Patch has {len(patch)} elements, but n_qubits is {n_qubits}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_qubits\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Truncate if too long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mq_output1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantum_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_l1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_output1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mq_output1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_output1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcapture_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_classical_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         res = qml.execute(\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/execution.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, transform_program, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, mcm_config, config, inner_transform)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trainable_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/interfaces/tensorflow.py\u001b[0m in \u001b[0;36mtf_execute\u001b[0;34m(tapes, execute_fn, jpc, device, differentiable)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams_dtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# make sure is float64 if data is float64.  May cause errors otherwise if device returns float32 precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_tapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36minner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracked_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDefaultExecutionConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/devices/modifiers/simulator_tracking.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muntracked_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDefaultExecutionConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntracked_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantumScript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mexecute_circuits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36mexecute_circuits\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                         \u001b[0mexecute_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcirc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36m_execute_estimator\u001b[0;34m(self, circuit, session)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# that right now feels excessive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mcirc_and_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiled_circuits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpauli_observables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         result = estimator.run(\n\u001b[0m\u001b[1;32m    664\u001b[0m             \u001b[0mcirc_and_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_shots\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_runtime/estimator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pubs, precision)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The precision value must be strictly greater than 0.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mcoerced_pubs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEstimatorPub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mvalidate_estimator_pubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced_pubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced_pubs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_runtime/estimator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The precision value must be strictly greater than 0.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mcoerced_pubs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEstimatorPub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mvalidate_estimator_pubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced_pubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced_pubs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/primitives/containers/estimator_pub.py\u001b[0m in \u001b[0;36mcoerce\u001b[0;34m(cls, pub, precision)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return cls(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mobservables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/primitives/containers/estimator_pub.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, circuit, observables, parameter_values, precision, validate)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/primitives/containers/estimator_pub.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mnum_qubits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_qubits\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    189\u001b[0m                     \u001b[0;34mf\"The number of qubits of the circuit ({self.circuit.num_qubits}) does \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0;34mf\"not match the number of qubits of the {i}-th observable ({num_qubits}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of qubits of the circuit (127) does not match the number of qubits of the (0,)-th observable (4)."
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "print(\"Starting training on 60 images (30 each of class 0 and 5)...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "epochs = 10\n",
        "batch_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    # Shuffle training data each epoch\n",
        "    shuffle_indices = np.random.permutation(len(train_images_selected))\n",
        "    shuffled_images = tf.gather(train_images_selected, shuffle_indices)\n",
        "    shuffled_labels = tf.gather(train_labels_selected, shuffle_indices)\n",
        "\n",
        "    for i in range(len(shuffled_images)):\n",
        "        img = shuffled_images[i]\n",
        "        label = shuffled_labels[i]\n",
        "\n",
        "        loss, predictions = train_step(img, tf.constant(label, dtype=tf.float32))\n",
        "        epoch_loss += loss.numpy()\n",
        "\n",
        "        predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
        "        if predicted_class == label:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    avg_loss = epoch_loss / len(shuffled_images)\n",
        "    accuracy = correct_predictions / len(shuffled_images)\n",
        "    batch_losses.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d}/{epochs} | Loss: {avg_loss:.6f} | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwG-FF_HaBpq"
      },
      "source": [
        "Test loop iterates over all test samples (default 1000 samples, 100 per class).\n",
        "\n",
        "Calculates loss, predictions, and accuracy per sample, accumulating totals.\n",
        "\n",
        "Tracks class-wise accuracy for detailed performance analysis.\n",
        "\n",
        "Prints progress every 100 samples and overall results after testing.\n",
        "\n",
        "Visualizes training loss curve and confusion matrix for model insights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8tTNUwtVSk8"
      },
      "outputs": [],
      "source": [
        "# Testing function\n",
        "@tf.function\n",
        "def test_step(x_img, y_label):\n",
        "    predictions = forward(x_img)\n",
        "    loss = loss_fn(tf.reshape(y_label, (1,)), predictions)\n",
        "    predicted_class = tf.argmax(predictions, axis=1)[0]\n",
        "    return loss, predictions, predicted_class\n",
        "\n",
        "def evaluate_model(x_test, y_test, num_samples=None):\n",
        "    \"\"\"Evaluate model on test data\"\"\"\n",
        "    if num_samples is None:\n",
        "        num_samples = x_test.shape[0]\n",
        "\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    class_correct = {}\n",
        "    class_total = {}\n",
        "\n",
        "    print(f\"Testing on {num_samples} samples...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        test_img = x_test[i]\n",
        "        test_label = y_test[i].numpy() if hasattr(y_test[i], 'numpy') else y_test[i]\n",
        "\n",
        "        loss, predictions, predicted_class = test_step(test_img, tf.constant(test_label))\n",
        "\n",
        "        total_loss += loss.numpy()\n",
        "        is_correct = (predicted_class.numpy() == test_label)\n",
        "        if is_correct:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        all_predictions.append(predicted_class.numpy())\n",
        "        all_true_labels.append(test_label)\n",
        "\n",
        "        # Track class-wise accuracy\n",
        "        if test_label not in class_total:\n",
        "            class_total[test_label] = 0\n",
        "            class_correct[test_label] = 0\n",
        "        class_total[test_label] += 1\n",
        "        if is_correct:\n",
        "            class_correct[test_label] += 1\n",
        "\n",
        "        # Print progress every 100 samples\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Processed {i+1}/{num_samples} samples...\")\n",
        "\n",
        "    avg_loss = total_loss / num_samples\n",
        "    overall_accuracy = correct_predictions / num_samples\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"OVERALL RESULTS:\")\n",
        "    print(f\"Test Accuracy: {overall_accuracy:.4f} ({correct_predictions}/{num_samples})\")\n",
        "    print(f\"Average Loss: {avg_loss:.6f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Class-wise results\n",
        "    print(\"\\nCLASS-WISE ACCURACY:\")\n",
        "    print(\"-\" * 30)\n",
        "    for class_id in sorted(class_total.keys()):\n",
        "        acc = class_correct[class_id] / class_total[class_id] if class_total[class_id] > 0 else 0\n",
        "        print(f\"Class {class_id}: {acc:.4f} ({class_correct[class_id]}/{class_total[class_id]})\")\n",
        "\n",
        "    return overall_accuracy, avg_loss, all_predictions, all_true_labels\n",
        "\n",
        "# Test the model\n",
        "print(\"Testing model performance on all classes...\")\n",
        "test_accuracy, test_loss, predictions, true_labels = evaluate_model(test_images_balanced, test_labels_balanced)\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(batch_losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot confusion matrix visualization\n",
        "plt.subplot(1, 2, 2)\n",
        "from collections import Counter\n",
        "confusion_data = Counter([(true, pred) for true, pred in zip(true_labels, predictions)])\n",
        "\n",
        "# Create confusion matrix\n",
        "confusion_matrix = np.zeros((10, 10))\n",
        "for (true_label, pred_label), count in confusion_data.items():\n",
        "    confusion_matrix[true_label, pred_label] = count\n",
        "\n",
        "plt.imshow(confusion_matrix, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        plt.text(j, i, int(confusion_matrix[i, j]),\n",
        "                ha=\"center\", va=\"center\", color=\"red\" if confusion_matrix[i, j] > 50 else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAnalysis Summary:\")\n",
        "print(\"- The model was trained on 60 images (30 each of class 0 and 5)\")\n",
        "print(\"- Tested on 1000 images (100 from each of the 10 classes)---> basically on 200 images\")\n",
        "print(\"- Classes 0 and 5 should show better performance since they were in training\")\n",
        "print(\"- Other classes rely on the model's ability to generalize\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}